{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stichometry Versus Syntax in the Song of Songs\n",
    "\n",
    "This notebook compares the stichometric boundaries of the Song of Songs as found in BHQ and Roberts 2001 dissertation, \"Let Me See Your Form\" against the clause boundaries found in ETCBC4b.\n",
    "\n",
    "Stichometry data was gathered during my previous master's thesis, \"Clause Syntax in the Song of Songs: A Preliminary Study.\" (Southeastern Baptist Theological Seminary, 2016). \n",
    "\n",
    "### To Do / Ideas\n",
    "* Export results and data to a spreadsheet so that non-programmers can still validate my findings for themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Legacy Data\n",
    "\n",
    "We load the ETCBC4b dataset which conforms with the cola slot numbers gathered during my 2016 thesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 2.3.6\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "111 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     1.35s B oslots               from /Users/Cody/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.02s B book                 from /Users/Cody/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.00s Feature overview: 105 for nodes; 5 for edges; 1 configs; 7 computed\n",
      "    10s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "# initialize Text-Fabric and load the ETCBC4b data\n",
    "\n",
    "from tf.fabric import Fabric\n",
    "\n",
    "TF = Fabric(locations='/Users/Cody/github/text-fabric-data-legacy',\n",
    "            modules='hebrew/etcbc4b')\n",
    "\n",
    "api = TF.load('''\n",
    "                book\n",
    "                oslots\n",
    "              ''')\n",
    "\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load all the clause nodes in the Song of Songs\n",
    "\n",
    "# get Song's book node\n",
    "song_node = next(book for book in F.book.s('Canticum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEMPORARY? WORKAROUND FOR OSLOTS\n",
    "\n",
    "def get_oslots(object_type, corpus):\n",
    "    '''\n",
    "    gathers the oslot ranges for a given otype & corpus\n",
    "    returns a set of strings that are the oslot ranges\n",
    "    requires a string otype and a book node integer.\n",
    "    '''\n",
    "\n",
    "    oslots = set()\n",
    "\n",
    "    objects = L.d(corpus, otype=object_type)\n",
    "    \n",
    "    # add slot ranges to set as string\n",
    "    for obj in objects:\n",
    "        slots = L.d(obj, otype='word')\n",
    "        oslots.add('{},{}'.format(slots[0], slots[-1]))\n",
    "        \n",
    "    return oslots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all of the slot ranges for linguistic objects in the Song of Songs. \n",
    "\n",
    "These will be used to compare with cola slot ranges. Some ranges may agree with the clause_atom, others with the sentence, others with phrases, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4329 oslot ranges loaded\n",
      "objects loaded:  verse, half_verse, sentence, sentence_atom, clause, clause_atom, phrase, phrase_atom, subphrase\n"
     ]
    }
   ],
   "source": [
    "# do not gather slot ranges for these objects\n",
    "omit_objects = {'book', 'chapter', 'word'}\n",
    "\n",
    "# get all otypes in database save ommited\n",
    "all_otypes = tuple(otype for otype in F.otype.all\n",
    "                      if otype not in omit_objects)\n",
    "\n",
    "\n",
    "# map otypes to a set of their oslot ranges\n",
    "oslots_by_otype = collections.OrderedDict()\n",
    "\n",
    "for otype in all_otypes:\n",
    "    oslots = get_oslots(otype, song_node)\n",
    "    \n",
    "    # add to dict\n",
    "    oslots_by_otype[otype] = oslots\n",
    "    \n",
    "# count up the oslots ranges!\n",
    "oslot_range_count = len(tuple(oslots for otype in oslots_by_otype\n",
    "                                for oslots in oslots_by_otype[otype]))\n",
    "# show results\n",
    "print(oslot_range_count, 'oslot ranges loaded')\n",
    "print('objects loaded: ', ', '.join(oslots_by_otype.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all the oslot ranges for the cola in the BHQ and Roberts sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421 slots loaded for roberts\n",
      "401 slots loaded for bhq\n"
     ]
    }
   ],
   "source": [
    "# draw in the stichometry data for both Roberts and BHQ\n",
    "\n",
    "sticho_sources = {'bhq':'BhqStichometry.csv', \n",
    "                  'roberts':'RobertsStichometry.csv'}\n",
    "\n",
    "# sources as keys; slot ranges as values stored as set\n",
    "sticho_slots = {}\n",
    "\n",
    "# open each source file and get slot ranges\n",
    "for source, file in sticho_sources.items():\n",
    "    with open(file) as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        \n",
    "        # get a set of all slot ranges \n",
    "        slots = set('{},{}'.format(line[1], line[2])\n",
    "                        for line in reader)\n",
    "        \n",
    "        # save to dict keyed by source name\n",
    "        sticho_slots[source] = slots\n",
    "            \n",
    "# print length of sources \n",
    "for source, slots in sticho_slots.items():\n",
    "    print(len(slots), 'slots loaded for', source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Statistics\n",
    "\n",
    "We compare the sources at the same time against the clause boundaries in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dict of dicts with sources as keys, match dicts as values\n",
    "# match dicts contain otype keys with slot sets as values\n",
    "matched_objects = collections.defaultdict(dict)\n",
    "\n",
    "# find matches and store to matched_objects\n",
    "for source, source_slots in sticho_slots.items():\n",
    "    \n",
    "    # find matches and save as sets\n",
    "    for otype, otype_slots in oslots_by_otype.items():\n",
    "        matches = source_slots & otype_slots\n",
    "        matched_objects[source][otype] = matches\n",
    "    \n",
    "    # identify and store slot ranges with no matches\n",
    "    all_matches = set(match for otype in matched_objects[source]\n",
    "                        for match in matched_objects[source][otype])\n",
    "    matched_objects[source]['no_match'] = source_slots - all_matches\n",
    "    \n",
    "    # save all slots for percentage calcs\n",
    "    matched_objects[source]['all_cola'] = source_slots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### present basic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** roberts **\n",
      "all_cola  --  421\n",
      "clause_atom  --  250\n",
      "clause  --  248\n",
      "sentence  --  139\n",
      "sentence_atom  --  139\n",
      "no_match  --  87\n",
      "phrase_atom  --  56\n",
      "phrase  --  51\n",
      "half_verse  --  35\n",
      "subphrase  --  1\n",
      "verse  --  1\n",
      "\n",
      "\n",
      "** bhq **\n",
      "all_cola  --  401\n",
      "clause  --  233\n",
      "clause_atom  --  230\n",
      "sentence  --  140\n",
      "sentence_atom  --  140\n",
      "no_match  --  82\n",
      "phrase_atom  --  50\n",
      "half_verse  --  42\n",
      "phrase  --  42\n",
      "verse  --  1\n",
      "subphrase  --  0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for source, match_data in matched_objects.items():\n",
    "\n",
    "    # count the matches \n",
    "    match_counts = tuple((otype, len(matches))\n",
    "                             for otype, matches in match_data.items()\n",
    "                        )\n",
    "    \n",
    "    # order the matches \n",
    "    match_data = sorted(match_counts, \n",
    "                        key = lambda s: s[-1], \n",
    "                        reverse=True)\n",
    "    \n",
    "    # print results\n",
    "    print('**', source, '**')\n",
    "    for otype, matches in match_data:\n",
    "        print(otype, ' -- ', matches)\n",
    "        \n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
